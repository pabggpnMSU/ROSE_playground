{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UQ for an Optical Potential using ROSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (if you don't have it already)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nuclear-rose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install surmise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rose\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from scipy.stats import qmc\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sps\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import datetime\n",
    "import corner\n",
    "import surmise\n",
    "from surmise.emulation import emulator\n",
    "from surmise.calibration import calibrator\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Scattering System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 40  # mass of the target\n",
    "target_name=\"Ca\"\n",
    "# asymptotic energy and wavenumber in center-of-mass (COM) frame\n",
    "energy = 14  # MeV\n",
    "# how many partial waves should we calculate?\n",
    "l_max = 10\n",
    "l_list = list(range(l_max + 1))\n",
    "# domain of the differential cross section; the observable we want to emulate. We are setting them as equally spaced angles between 1 and 179 but this can be changed\n",
    "angles = np.linspace(1, 179, 179)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we either provide the experimental data we want to use, or a subset of angles and ROSE will generate mock data on them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_provided_data =0  #Leave this as zero if user is only providing the \"x\" locations (the angles)\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    "#If providing data directly:\n",
    "# angles_theta=\n",
    "# anglesX=angles_theta- np.full(len(angles_theta), 1) #Moving the angles location by one because of how python works\n",
    "# y_measured =   #Valueus of the observed cross section\n",
    "# yerr=  #Errors of the observed cross section\n",
    "# flag_provided_data=1    #Mark this as \"1\" if data is provided by user\n",
    "##################################################\n",
    "\n",
    "\n",
    "##################################################\n",
    "#A subset of the angles in which we will deal with data\n",
    "angles_theta=np.arange(20,160,5)\n",
    "anglesX=angles_theta- np.full(len(angles_theta), 1) #Moving the angles location by one because of how python works\n",
    "\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally some details and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "AMU = 931.494102  # MeV/c^2, Particle Data Group\n",
    "MASS_N = 1.008665 * AMU  # MeV/c^2 PDG\n",
    "MASS_P = 1.007276 * AMU  # MeV/c^2 PDG\n",
    "MASS_CHARGED_PION = 139.57039  # MeV/c^2\n",
    "B_40CA = 342.0522  # BMEX\n",
    "\n",
    "MASS_40CA = 20 * MASS_P + 20 * MASS_N - B_40CA\n",
    "MU = (\n",
    "    MASS_40CA * MASS_N / (MASS_40CA + MASS_N)\n",
    ")  # reduced mass - we will do calculations in COM frame\n",
    "\n",
    "#Alternatively you could define it as:\n",
    "#MU = (AMU * A / (A+1)  ) \n",
    "\n",
    "\n",
    "k = np.sqrt(2 * MU * energy) / rose.constants.HBARC\n",
    "\n",
    "rho=np.linspace(1e-6, 8*np.pi,2000)\n",
    "s_0=6 * np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of interaction for volume term\n",
    "def wood_saxon(r, R, a):\n",
    "    return 1 / (1 + np.exp((r - R) / a))\n",
    "\n",
    "\n",
    "# shape of interaction for surface-peaked and spin-orbit coupling terms\n",
    "def wood_saxon_prime(r, R, a):\n",
    "    return -1 / a * np.exp((r - R) / a) / (1 + np.exp((r - R) / a)) ** 2\n",
    "\n",
    "\n",
    "# total potential with a real and central term (with the same geometry)\n",
    "# and imaginary surface-peaked term, but no SO coupling\n",
    "def optical_potential(r, theta):\n",
    "    Vv, Wv, Wd, Vso, Rv, Rd, Rso, av, ad, aso = theta\n",
    "    return (-1j * Wv - Vv) * wood_saxon(r, Rv, av) + (4j * ad * Wd) * wood_saxon_prime(\n",
    "        r, Rd, ad\n",
    "    )\n",
    "\n",
    "\n",
    "# spin orbit interaction constant\n",
    "mso = rose.constants.HBARC / MASS_CHARGED_PION\n",
    "\n",
    "\n",
    "# spin-orbit (SO) coulpling term - a function of l dot s, l being the orbital angular momentum\n",
    "# and s being the spin of the neutron\n",
    "def spin_orbit_potential(r, theta, ldots):\n",
    "    Vv, Wv, Wd, Vso, Rv, Rd, Rso, av, ad, aso = theta\n",
    "    return (Vso) * mso**2 * ldots * wood_saxon_prime(r, Rso, aso) / r\n",
    "\n",
    "\n",
    "# the total number of parameters\n",
    "nparams = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the parameters central value and the box around which we will train with the emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the value of the parameters coming from the Koning-Delaroche parametrization.\n",
    "# Taken from https://www-nds.iaea.org/RIPL-3/\n",
    "VvKD = 48.9\n",
    "WvKD = 1.2\n",
    "WdKD = 7.7\n",
    "VsoKD = 5.5\n",
    "\n",
    "\n",
    "RvKD = 1.19* 40 ** (1.0 / 3.0)\n",
    "RdKD = 1.29* 40 ** (1.0 / 3.0)\n",
    "RsoKD = 1.00 * 40 ** (1.0 / 3.0)\n",
    "\n",
    "avKD = 0.67\n",
    "adKD = 0.67\n",
    "asoKD = 0.59\n",
    "\n",
    "alphaKD = np.array(\n",
    "    [VvKD, WvKD, WdKD, VsoKD, RvKD, RdKD, RsoKD, avKD, adKD, asoKD]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#The following are the center of the parameters to train the emulator\n",
    "Vv0 = 45\n",
    "Wv0 = 2\n",
    "Wd0 = 5\n",
    "Vso = 5\n",
    "\n",
    "\n",
    "\n",
    "Rv0 = 4\n",
    "\n",
    "Rd0 = 4\n",
    "Rso = 4\n",
    "\n",
    "av0 = 0.5\n",
    "\n",
    "ad0 = 0.5\n",
    "aso = 0.5\n",
    "\n",
    "\n",
    "#This is the center of our prior and around where we will train our RBM emulator\n",
    "alphaCentral = np.array([Vv0, Wv0, Wd0, Vso, Rv0, Rd0, Rso, av0 , ad0, aso])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaleTraining = 0.3\n",
    "\n",
    "bounds = np.array(\n",
    "    [\n",
    "        alphaCentral - np.fabs(alphaCentral * scaleTraining),\n",
    "        alphaCentral + np.fabs(alphaCentral * scaleTraining),\n",
    "    ]\n",
    ").T\n",
    "\n",
    "\n",
    "def sample_points(npoints, bounds,initial_seed=None):\n",
    "    sampler = qmc.LatinHypercube(d=len(bounds), seed=initial_seed)\n",
    "    sample = sampler.random(npoints)\n",
    "    scaled = qmc.scale(sample, bounds[:, 0], bounds[:, 1])\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we specify how many samples we want for training the emulator (both wave function  and operator expansion), and how many for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 30\n",
    "\n",
    "seed_train=142857\n",
    "training_samples = sample_points(n_train, bounds,initial_seed=seed_train)\n",
    "# np.savetxt(\"train_params_calibration.txt\",training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_EIM=1000\n",
    "\n",
    "seed_EIM=142857*3\n",
    "\n",
    "train_EIM = sample_points(n_train_EIM, bounds,initial_seed=seed_EIM)\n",
    "# np.savetxt(\"train_params_EIM_calibration.txt\",train_EIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test=10\n",
    "seed_test=142857*2\n",
    "\n",
    "test_samples = sample_points(n_test, bounds,initial_seed=seed_test)\n",
    "\n",
    "\n",
    "## np.savetxt(\"test_params_calibration.txt\",test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the emulator, we can choose how many basis for both the wave functions and the operastors\n",
    "\n",
    "n_basis = 15\n",
    "n_eim = 15\n",
    "\n",
    "interactions = rose.InteractionEIMSpace(\n",
    "    optical_potential,\n",
    "    nparams,\n",
    "    MU,\n",
    "    energy,\n",
    "    l_max,\n",
    "    training_info=train_EIM,\n",
    "    is_complex=True,\n",
    "    spin_orbit_potential=spin_orbit_potential,\n",
    "    explicit_training = True,\n",
    "    rho_mesh=rho,\n",
    "    n_basis=n_eim,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:33<00:00,  3.03s/it]\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/rose/utility.py:86: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return np.hstack([1/(2*s_c) * (3 - (s[ii]/s_c)**2), 1/s[jj]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "saeMCMC_fullangles = rose.ScatteringAmplitudeEmulator.from_train(\n",
    "    interactions,\n",
    "    training_samples,\n",
    "    l_max,\n",
    "    s_mesh=rho,\n",
    "    s_0=s_0,\n",
    "    n_basis=n_basis,\n",
    "    angles=angles/ 180 * np.pi,\n",
    "    hf_tols=[\n",
    "        10 ** (-7),\n",
    "        10 ** (-7),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:39<00:00,  3.93s/it]\n"
     ]
    }
   ],
   "source": [
    "# calculate the exact differential cross section for the test parameters we sampled\n",
    "test_CS = []\n",
    "for params in tqdm(test_samples):\n",
    "    test_CS.append(saeMCMC_fullangles.exact_dsdo(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's plot the differential scattering cross section for each of these samples test points!\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "\n",
    "\n",
    "for i in range(n_test):\n",
    "    ax.plot(angles, test_CS[i])\n",
    "ax.set_yscale(\"log\")\n",
    "plt.xlim([0, 180])\n",
    "plt.xlabel(r\"$\\theta$ [$^\\circ$]\")\n",
    "plt.ylabel(r\"$\\frac{d \\sigma}{d \\Omega}$ [mb/sr]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets have some quantification on the level of error that the emulator is making across the test set. You can also start getting a feeling for its timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = []\n",
    "times_list = []\n",
    "for i in range(len(test_samples)):\n",
    "        st = time.time()\n",
    "        predicted = saeMCMC_fullangles.emulate_dsdo(test_samples[i])\n",
    "        et = time.time()\n",
    "        prediction_list.append(predicted)\n",
    "        times_list.append(et - st)\n",
    "\n",
    "residual_list_relative = []\n",
    "residual_list_all = []\n",
    "residual_list_median = []\n",
    "\n",
    "\n",
    "#Calculating residuals over all the angles:\n",
    "for i in range(len(test_samples)):\n",
    "    residual_list_relative.append(\n",
    "        # 100* np.fabs((prediction_list[i] - test_CS[i])) / (test_CS[i])\n",
    "        100* ((prediction_list[i] - test_CS[i])) / (test_CS[i])\n",
    "    )\n",
    "    residual_list_median.append(np.median(residual_list_relative[i]))\n",
    "    residual_list_all.append(prediction_list[i] - test_CS[i])\n",
    "residual_list_relative = np.array(residual_list_relative)    \n",
    "residual_list_all=np.array(residual_list_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now plot the error for each angle. If you selected just a few test cases the histograms might look a bit empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list=[]\n",
    "residuals=residual_list_relative.T[anglesX]\n",
    "\n",
    "plots_per_row = 5\n",
    "num_of_rows = len(residuals) // plots_per_row + (len(residuals) % plots_per_row > 0)\n",
    "\n",
    "# Set up the figure size, you can adjust it as needed\n",
    "plt.figure(figsize=(15, num_of_rows * 3))\n",
    "\n",
    "# Loop over the list of residuals and create a histogram for each\n",
    "for i, residual in enumerate(residuals):\n",
    "    # Create a subplot for each histogram\n",
    "    ax=plt.subplot(num_of_rows, plots_per_row, i + 1)\n",
    "    \n",
    "#     # Plot the histogram\n",
    "#     plt.hist(residual, bins=20, alpha=0.75, edgecolor='black', density=True)\n",
    "    \n",
    "    # Plot the histogram and normalize it\n",
    "    ax.hist(residual,  alpha=0.75, edgecolor='black', density=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Fit a Gaussian distribution to the residuals\n",
    "    mu=np.mean(residuals[i])\n",
    "    std = np.std(residuals[i])\n",
    "    rmse_list.append(np.sqrt(mu**2+std**2))\n",
    "\n",
    "    \n",
    "    # Plot the Gaussian distribution\n",
    "    xmin=np.min(residuals[i])\n",
    "    xmax = np.max(residuals[i])\n",
    "\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = sps.norm.pdf(x, mu, std)\n",
    "    ax.plot(x, p, 'r', linewidth=2)\n",
    "    \n",
    "                     \n",
    "                     \n",
    "    ax.axvline(x=0, color='magenta', linestyle='--', linewidth=1.5)\n",
    "    # Optional: Set a title or labels\n",
    "    plt.title(f'Angle {anglesX[i]+1}')\n",
    "    plt.xlabel('Relative Residual (percentage)')\n",
    "    plt.ylabel('Density')\n",
    "    \n",
    "    # Optional: Set a tight layout so the plots are neatly arranged\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the pseudo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_provided_data==0:\n",
    "\n",
    "    #Percentage error to be used in the cs\n",
    "    sigma_err=0.1\n",
    "\n",
    "    # Defining the data we are interest in\n",
    "\n",
    "    #Angles Matched to reproduce Figure 6 from: https://iopscience.iop.org/article/10.1088/1361-6471/abba72\n",
    "\n",
    "    angles_theta=np.arange(20,160,5)\n",
    "\n",
    "\n",
    "    anglesX=angles_theta- np.full(len(angles_theta), 1) #Moving the angles location by one because of how python works\n",
    "    f_exact = saeMCMC_fullangles.exact_dsdo(alphaKD)\n",
    "\n",
    "    \n",
    "    yperfect =f_exact[anglesX]\n",
    "    yerr=yperfect*sigma_err\n",
    "\n",
    "    np.random.seed(142857)\n",
    "\n",
    "    y_measured=[]\n",
    "\n",
    "    for i in range(len(yperfect)):\n",
    "        y_measured.append(yperfect[i]+np.random.normal(0, yperfect[i]*sigma_err))\n",
    "    \n",
    "    y_measured=np.array(y_measured)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify accordingly if you provided the experimental data directly (flag_provided_data==1)\n",
    "fig, ax = plt.subplots(figsize=(6,4),dpi=300)\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "\n",
    "ax.plot(angles,f_exact)\n",
    "ax.scatter(anglesX, yperfect,color='k',label='Exact Values')\n",
    "# ax.scatter(anglesX, y_measured,color='r',label=' \"Measured\" values')\n",
    "ax.errorbar(anglesX, y_measured, yerr=np.array(y_measured)*0.2, fmt=\"o\", c=\"r\",label=' \"Measured\" values')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(r'$\\theta$')\n",
    "ax.set_ylabel(r'$d\\sigma/d\\Omega$ (mb)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Bayesian with surmise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use surmise, another BAND-developed package for connecting all the tools and softwares (such as our ROSE emulator) for performing Bayesian analysis.\n",
    "\n",
    "Check out surmise's documentation webpage for more information: https://surmise.readthedocs.io/en/latest/\n",
    "\n",
    "Our sample rate for the emulator is around 1-3 miliseconds, which means around 20k samples per minute. We are choosing a relatively small amount of samples and chains to have the calibration done in a couple of minutes. You can of course run it for longer and obtain millions of samples to build very detailed and rich corner plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this default we are assuming uncorrelated Gaussian priors. Advanced users can provide covariance matrices for correlations\n",
    "\n",
    "# Specifying the priors, we believe the answer that explains the data shouldn't be too far away from the KD parameters\n",
    "alphaCentralPrior = alphaCentral\n",
    "\n",
    "#We are using Gaussian priors with a standard deviation of 25% of their respective centers\n",
    "SigmasPrior = [abs(param_val * 0.25) for param_val in alphaCentralPrior]\n",
    "\n",
    "# We use a smaller scale for the starting values of the MCMC chains so that we minimize the chances of one\n",
    "# starting in a negative value of the diffuseness or the radii\n",
    "\n",
    "#This scale is very important: since the optical potential posterior parameter surface is highly multimodal we would like to limit ourself for this tutorial\n",
    "#to study a vicinity of the main mode closer to our prior. We will start our walkers very close to the prior center.\n",
    "MCMCScale = [abs(param_val * 0.05) for param_val in alphaCentralPrior]\n",
    "\n",
    "# We need to provide a scale for the emulator error. We could estimate it directly from the residuals list defined above, but since we had only a few samples,\n",
    "# and since we have observed the emulator error can grow to around 1% when deviating too far away from the training region, we will use this 1% as a\n",
    "# conservative measure. The user should check out later if this assumption holds in the visited posterior samples\n",
    "Emulator_error_value=0.01\n",
    "\n",
    "Emulator_error_list=y_measured*Emulator_error_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the data in the format that surmise needs\n",
    "\n",
    "X = np.copy(angles_theta)/180*np.pi\n",
    "\n",
    "y = np.copy(y_measured)\n",
    "\n",
    "obsvar = 1.0 * np.square(yerr) + np.square(Emulator_error_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important settings for the calibration\n",
    "\n",
    "StepSizes0 = 0.007 * np.abs( alphaCentral )\n",
    "\n",
    "numsamp = 5000\n",
    "total_chains = 10\n",
    "numcores = 8\n",
    "BurnSamples0 = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some definitions for surmise\n",
    "\n",
    "class prior_scattering:\n",
    "    \"\"\" This defines the class instance of priors provided to the method. \"\"\"\n",
    "\n",
    "\n",
    "    def lpdf(theta):\n",
    "        \n",
    "        total_prior_pdf=sps.norm.logpdf(theta[:, 0], alphaCentralPrior[0],SigmasPrior[0] )\n",
    "        \n",
    "        for i in range(1,len(alphaCentralPrior)):\n",
    "            total_prior_pdf=total_prior_pdf+ sps.norm.logpdf(theta[:, i], alphaCentralPrior[i],SigmasPrior[i] )\n",
    "            \n",
    "            \n",
    "            \n",
    "        return (total_prior_pdf).reshape((len(theta), 1))\n",
    "\n",
    "\n",
    "    def rnd(n):\n",
    "        totalRandomSamples=[]\n",
    "        for i in range(len(alphaCentralPrior)):\n",
    "            totalRandomSamples.append(sps.norm.rvs( alphaCentralPrior[i], MCMCScale[i],   size=n))\n",
    "        \n",
    "        totalRandomSamplesNumpy=np.array(totalRandomSamples)\n",
    "        \n",
    "        return totalRandomSamplesNumpy.T\n",
    "        \n",
    "def calibration_runner(rbm,x,y,obsvar,test_params,numsamp,i,caldir):\n",
    "   \n",
    "    cal = calibrator(emu=rbm,\n",
    "                   y=y,\n",
    "                   x=x,\n",
    "                   thetaprior=prior_scattering, \n",
    "                   method='directbayes',\n",
    "                   yvar=obsvar, \n",
    "                   args={\n",
    "                       'theta0': test_params.reshape(1,nparams),\n",
    "                       'sampler': 'metropolis_hastings',\n",
    "                       'numsamp' : numsamp,\n",
    "                       'stepType' : 'normal',\n",
    "                       'stepParam' : StepSizes0,\n",
    "                       'burnSamples' : BurnSamples0,\n",
    "                       'verbose': True\n",
    "                   })\n",
    "                       \n",
    " \n",
    "    calfile = os.path.join(caldir,\"caltheta_{}.out\".format(i))\n",
    "    np.savetxt(calfile,cal.info['thetarnd'])\n",
    "\n",
    "    return cal.info['thetarnd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(142857)\n",
    "\n",
    "#Creating the calibration folder to store the samples\n",
    "caldir = os.path.join(\n",
    "    os.getcwd(), \"Cal-\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    ")\n",
    "os.makedirs(caldir, exist_ok=True)\n",
    "\n",
    "rand_params = prior_scattering.rnd(total_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = emulator(method='nuclear-ROSE', args={'rose_emu': saeMCMC_fullangles, \n",
    "#                                             'emu_variance_constant': Emulator_Error, \n",
    "                                            'angle_atol': 1e-1\n",
    "                                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And now we start the chains!\n",
    "\n",
    "st = time.time()\n",
    "sep_chains = []\n",
    "chain0 = calibration_runner(rbm, X, y, obsvar, rand_params[0], numsamp, 0, caldir)\n",
    "sep_chains.append(chain0)\n",
    "all_chains = chain0\n",
    "\n",
    "for ij in tqdm(range(total_chains - 1)):\n",
    "    current_cal = calibration_runner(\n",
    "        rbm, X, y, obsvar, rand_params[ij], numsamp, ij + 1, caldir\n",
    "    )\n",
    "\n",
    "    all_chains = np.vstack(\n",
    "        (\n",
    "            all_chains,\n",
    "            current_cal,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    sep_chains.append(current_cal)\n",
    "\n",
    "    print(\"Percentage Completed \", int((ij + 1) / (total_chains - 1) * 100))\n",
    "    \n",
    "sep_chains = np.array(sep_chains)\n",
    "et = time.time()\n",
    "print(\"Total time:\", et - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking that the estimated error of the emulator is consistent (around or below) what we estimated for it before running the calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples_MCMC=20\n",
    "rng = np.random.default_rng()\n",
    "test_samples_posterior= rng.choice(all_chains, (test_samples_MCMC), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the exact differential cross section for the 100 test parameters from the posterior\n",
    "test_CS_posterior = []\n",
    "for params in tqdm(test_samples_posterior):\n",
    "    test_CS_posterior.append(saeMCMC_fullangles.exact_dsdo(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list_posterior = []\n",
    "times_list_posterior = []\n",
    "for i in range(len(test_samples_posterior)):\n",
    "        st = time.time()\n",
    "        predicted = saeMCMC_fullangles.emulate_dsdo(test_samples_posterior[i])\n",
    "        et = time.time()\n",
    "        prediction_list_posterior.append(predicted)\n",
    "        times_list_posterior.append(et - st)\n",
    "\n",
    "residual_list_relative_posterior = []\n",
    "residual_list_all_posterior = []\n",
    "residual_list_median_posterior = []\n",
    "\n",
    "\n",
    "#Calculating residuals over all the angles:\n",
    "for i in range(len(test_samples_posterior)):\n",
    "    residual_list_relative_posterior.append(\n",
    "        100*((prediction_list_posterior[i] - test_CS_posterior[i])) / (test_CS_posterior[i])\n",
    "    )\n",
    "    residual_list_median_posterior.append(np.median(residual_list_relative_posterior[i]))\n",
    "    residual_list_all_posterior.append(prediction_list_posterior[i] - test_CS_posterior[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rmse_list_posterior=[]\n",
    "residuals_posterior=np.array(residual_list_relative_posterior).T[anglesX]\n",
    "\n",
    "\n",
    "\n",
    "plots_per_row = 5\n",
    "num_of_rows = len(residuals_posterior) // plots_per_row + (len(residuals_posterior) % plots_per_row > 0)\n",
    "\n",
    "plt.rc(\"xtick\", labelsize=15)\n",
    "plt.rc(\"ytick\", labelsize=15)\n",
    "\n",
    "# Set up the figure size, you can adjust it as needed\n",
    "plt.figure(figsize=(15, num_of_rows * 3))\n",
    "\n",
    "\n",
    "\n",
    "# Loop over the list of residuals and create a histogram for each\n",
    "for i, residual in enumerate(residuals_posterior):\n",
    "    # Create a subplot for each histogram\n",
    "    ax=plt.subplot(num_of_rows, plots_per_row, i + 1)\n",
    "    \n",
    "    # Plot the histogram and normalize it\n",
    "    ax.hist(residual,  alpha=0.75, edgecolor='black', density=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Fit a Gaussian distribution to the residuals\n",
    "    mu=np.mean(residuals_posterior[i])\n",
    "    std = np.std(residuals_posterior[i])\n",
    "    rmse_list_posterior.append(np.sqrt(mu**2+std**2))\n",
    "\n",
    "    \n",
    "    # Plot the Gaussian distribution\n",
    "    xmin=np.min(residuals_posterior[i])\n",
    "    xmax = np.max(residuals_posterior[i])\n",
    "\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = sps.norm.pdf(x, mu, std)\n",
    "    ax.plot(x, p, 'r', linewidth=2)\n",
    "    \n",
    "                     \n",
    "                     \n",
    "    ax.axvline(x=0, color='magenta', linestyle='--', linewidth=1.5)\n",
    "    # Optional: Set a title or labels\n",
    "    plt.title(f'Angle {anglesX[i]+1}')\n",
    "    plt.xlabel('Relative residual_posterior (percentage)')\n",
    "    plt.ylabel('Density')\n",
    "    # Optional: Set a tight layout so the plots are neatly arranged\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's plot the differential scattering cross section for each of these samples test points!\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    ax.plot(angles, test_CS_posterior[i])\n",
    "    ax.plot(angles, prediction_list_posterior[i],color=\"k\", linestyle=\"--\")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.xlim([0, 180])\n",
    "plt.xlabel(r\"$\\theta$ [$^\\circ$]\")\n",
    "plt.ylabel(r\"$\\frac{d \\sigma}{d \\Omega}$ [mb/sr]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results of the calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plotting routinge to make the gorgeous corner plots! For some reason we have to run it twice to make the label\n",
    "# size for the ticks to be correct\n",
    "\n",
    "plt.rc(\"xtick\", labelsize=29)\n",
    "plt.rc(\"ytick\", labelsize=29)\n",
    "\n",
    "bins_target=15\n",
    "ws = [abs(max(all_chains[:,i])-min(all_chains[:,i]))/bins_target for i in range(len(all_chains.T))]\n",
    "\n",
    "\n",
    "figure=corner.corner(all_chains,\n",
    "    labels=[\n",
    "        \"$V_v$\",\n",
    "        \"$W_v$\",\n",
    "        \"$W_d$\",\n",
    "        \"$V_{so}$\",\n",
    "#         \"$W_{so}$\",\n",
    "        \"$R_v$\",\n",
    "        \"$R_d$\",\n",
    "        \"$R_{so}$\",\n",
    "        \"$a_v$\",\n",
    "        \"$a_d$\",\n",
    "        \"$a_{so}$\"\n",
    "    ],\n",
    "    labelpad=0.3,\n",
    "    # bins=20,\n",
    "    bins=[int(abs(max(all_chains[:,i])-min(all_chains[:,i]))/ws[i]) for i in range(len(all_chains.T))],\n",
    "    label_kwargs={\"fontsize\": 50},\n",
    "    hist_kwargs={\"linewidth\": 3},\n",
    "    quantiles=None,\n",
    "    truths=alphaKD,\n",
    "    truth_color=\"r\",\n",
    "    smooth=(1.7),\n",
    "    smooth1d=1.0\n",
    ")\n",
    "\n",
    "\n",
    "dim=len(all_chains[0]) \n",
    "fudge_numbers=[1,1,1,1,1,1,1,1,1,1]\n",
    "ranges=[\n",
    "    [min(all_chains[:,i]) - 0.35*fudge_numbers[i]*( max(all_chains[:,i])-min(all_chains[:,i]) ),\n",
    "     max(all_chains[:,i]) + 0.35*fudge_numbers[i]*(max(all_chains[:,i])-min(all_chains[:,i]))\n",
    "    ] \n",
    "    \n",
    "    for i in range(len(all_chains.T))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Routine to plot the prior and to adjust the ticks\n",
    "axes = np.array(figure.axes).reshape((dim, dim))\n",
    "max_ticks=3\n",
    "for i in range(dim):\n",
    "    ax = axes[i, i]\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(max_ticks))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(max_ticks))\n",
    "    ax.set_xlim(ranges[i][0],ranges[i][1])\n",
    "    ax.axvline(alphaCentral[i], color=\"blue\")\n",
    "   \n",
    "\n",
    "    x_grid=np.linspace(ranges[i][0],ranges[i][1],200)\n",
    "    ax.plot(x_grid,len(all_chains)*ws[i]*sps.norm.pdf(x_grid, alphaCentral[i], SigmasPrior[i]),color='b',linewidth=2)\n",
    "    ax.fill_between(x_grid, len(all_chains)*ws[i]*sps.norm.pdf(x_grid, alphaCentral[i], SigmasPrior[i]), color='blue', alpha=0.1)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(max_ticks))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(max_ticks))\n",
    "\n",
    "\n",
    "\n",
    "    for j in range(i):\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(max_ticks))\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(max_ticks))\n",
    "        ax = axes[i, j]\n",
    "        ax.set_ylim(ranges[i][0],ranges[i][1])\n",
    "        ax.set_xlim(ranges[j][0],ranges[j][1])\n",
    "      \n",
    "        ax.axvline(alphaCentral[j], color=\"blue\")\n",
    "        ax.axhline(alphaCentral[i], color=\"blue\")\n",
    "        \n",
    "        ax.plot(alphaCentral[j], alphaCentral[i], \"sb\")\n",
    "        \n",
    "        \n",
    "        ax.xaxis.set_major_locator(MaxNLocator(max_ticks))\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(max_ticks))\n",
    "        \n",
    "width = 24\n",
    "height = 18\n",
    "figure.set_size_inches(width, height)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very interesting! In red we can see the original parametrization by Koning-Delaroche that we used to generate the data, while the blue lines are the actual prior, and the black ones the posterior. Most parameters are more or less around that value, while some shifted appreciably. Some parameters are very well constrained by the data, while others seem to just be constrained by the prior. \n",
    "\n",
    "Thanks to ROSE, we now can make these kinds of analysis VERY fast!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets look at how the chains developed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsChains = [\n",
    "    \"$V_v$\",\n",
    "    \"$W_v$\",\n",
    "    \"$W_d$\",\n",
    "    \"$V_{so}$\",\n",
    "    \"$W_{so}$\",\n",
    "    \"$R_v$\",\n",
    "    \"$R_d$\",\n",
    "    \"$R_{so}$\",\n",
    "    \"$a_v$\",\n",
    "    \"$a_d$\",\n",
    "    \"$a_{so}$\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XAll = np.arange(len(anglesX))\n",
    "\n",
    "plt.rc(\"xtick\", labelsize=15)\n",
    "plt.rc(\"ytick\", labelsize=15)\n",
    "fig, axs = plt.subplots(nparams, 1, figsize=(12, 12), sharex='all')\n",
    "\n",
    "for i in range(nparams):\n",
    "    axs[i].axhline(y=alphaKD[i],color='r')\n",
    "    axs[i].plot(sep_chains[:, :, i].T, alpha=0.65)\n",
    "    axs[i].set_ylabel(labelsChains[i], fontsize=18)\n",
    "\n",
    "plt.xlabel('MCMC samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting our final calibrated model alongside the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "plotting_samples=5000\n",
    "theta_rand = rng.choice(all_chains, (plotting_samples), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.8 s, sys: 32.9 s, total: 1min 20s\n",
      "Wall time: 46.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rndm_m = []\n",
    "\n",
    "for i in range(len(theta_rand)):\n",
    "    yvals_rand=saeMCMC_fullangles.emulate_dsdo(theta_rand[i])\n",
    "    rndm_m.append(yvals_rand +\n",
    "                   np.random.multivariate_normal(np.full(\n",
    "                       len(angles)\n",
    "                       ,0), np.diag( 1.0 * np.square(yvals_rand*sigma_err) + np.square(yvals_rand*Emulator_error_value)\n",
    "                   )))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/rose/free_solutions.py:52: DeprecationWarning: scipy.misc.derivative is deprecated in SciPy v1.10.0; and will be completely removed in SciPy v1.12.0. You may consider using findiff: https://github.com/maroba/findiff or numdifftools: https://github.com/pbrod/numdifftools\n",
      "  return derivative(lambda z: H_minus(z, ell, eta), rho, dx=dx)\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/rose/free_solutions.py:45: DeprecationWarning: scipy.misc.derivative is deprecated in SciPy v1.10.0; and will be completely removed in SciPy v1.12.0. You may consider using findiff: https://github.com/maroba/findiff or numdifftools: https://github.com/pbrod/numdifftools\n",
      "  return derivative(lambda z: H_plus(z, ell, eta), rho, dx=dx)\n"
     ]
    }
   ],
   "source": [
    "#Calculating the true cross section if we are working with pseudo data\n",
    "KD_cs=saeMCMC_fullangles.exact_dsdo(alphaKD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rc(\"xtick\", labelsize=50)  # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=50)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(20, 10),dpi=300)\n",
    "median = np.percentile(rndm_m, 50, axis=0)\n",
    "upper = np.abs(np.percentile(rndm_m, 97.5, axis=0))\n",
    "\n",
    "\n",
    "\n",
    "lower = np.abs(np.percentile(rndm_m, 2.5, axis=0))\n",
    "\n",
    "axs.plot(angles, 10*median, color=\"C0\", label='Median Prediction',linewidth=5)\n",
    "\n",
    "axs.plot(angles, 10*lower, color=\"C0\",linestyle=\"dashed\",linewidth=3,alpha=0.5)\n",
    "axs.plot(angles, 10*upper, color=\"C0\",linestyle=\"dashed\",linewidth=3,alpha=0.5)\n",
    "\n",
    "axs.fill_between(angles, 10*lower, 10*upper, color=\"C0\",alpha=0.5, label='95 percentile')\n",
    "\n",
    "# axs.scatter(angles_theta, 10*y, s=150, c=\"r\", label='Mock Data')\n",
    "axs.errorbar(angles_theta, 10*y, yerr=10*2 * yerr,linewidth=3,markersize=12, fmt=\"o\", c=\"r\",label='Synthetic Data')\n",
    "\n",
    "axs.set_yscale(\"log\")\n",
    "\n",
    "axs.set_xlabel(r\"$\\theta$ (deg)\", fontsize=50)\n",
    "axs.set_ylabel(r\"$d\\sigma/d\\Omega$ [mb/sr] \", fontsize=50)\n",
    "\n",
    "axs.plot(angles, 10*KD_cs, c=\"k\",linewidth=3,label='True Function')\n",
    "\n",
    "\n",
    "plt.title(r\"$^{40}\"+str(target_name)+\"(n,n)\" +str(energy) + \"MeV$\", fontsize=50)\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(fontsize='30')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And thats it, you have done it!! Now go forth and make lots and lots of good UQ with optical potentials :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Dirac.png\" width=\"600\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
